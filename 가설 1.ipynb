{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf5b03b-8b84-4c69-85f4-9edeb8d9e8fd",
   "metadata": {},
   "source": [
    "# 가설\n",
    " - 기존엔 벡터검색만 수행했음\n",
    " - 이 경우엔 단순 유사성만 검색하기 때문에, 의미는 전혀 다르지만 비슷한 오류 양상 체크는 불가한 단점이 존재.\n",
    " - BM25도 조합하여 각각 or 하이브리드 방식으로 말뭉치 내 입력 문장과 유사한 오류 문장을 검색하는 방식으로 변경\n",
    "\n",
    "## TODO: 추후 RAG 외 MCP도 응용해 볼 생각\n",
    " - 예를 들면, LLM이 직접 문장을 인식하고 나서, LLM이 오류인지 판단하게 한 후 이와 비슷한 양상을 국가 등을 필터한 후 말뭉치에서 능동적으로 검색\n",
    "\n",
    "# 생각\n",
    " - 말뭉치에서 에러 문장 / 올바른 문장 / 에러 형태소 배열 / 올바른 형태소 배열을 추출\n",
    " - 사용자가 문장 입력 시, 형태소 분석하여 위 4개 모두 검색\n",
    "   - 형태소 배열은 벡터 검색 불필요. BM25 사용\n",
    " - 형태소가 올바르지만, 잘못된 단어 사용 (예 - 결혼 / 계론) 과 같은 경우는?\n",
    "   - (확인해봐야 할 거 같은데) 형태소는 OK, 벡터비교는 낮게 나올거 같음.\n",
    "   - 그리고, 말뭉치에서 오타로 인한 오류라는 태그가 달려 있을거임. 이 오타는 어떻게 \"검출\" 하고, 동일한 사례를 어떻게 검색하나? LLM이 판단할 수 있는가?\n",
    "     - (만약 오타를 비슷하게 낸다면) 이런 케이스들은 벡터검색 일치가 높게 나올 거 같음. 그리고, 이 경우엔 반드시 **오타 오류** 를 포함하고 있어야 함.\n",
    "     - 대상이 초급이면, **오타 오류** 를 포함한 말뭉치에서 1차 검색하는게 좋을 수도 있음.\n",
    "   - **오타 오류** / **문법 오류** 두가지 케이스로 나눌 수 있나? -> **이 부분 논의 필요**\n",
    "     - 답변: 둘 다 많음. (**오타 오류** / **문법 오류** / **둘 다**)\n",
    "   - 형태소 기반으로 검색을 할때엔 레벤슈타인 알고리즘 사용 (rapidfuzz)\n",
    "     - 엘라스틱서치에서 관련 기능 지원 안해서, 1차로 검색한 후 2차 내에서 검색 보완하는 식으로 사용해야 할 듯\n",
    "\n",
    "# 검색 순서\n",
    "  1. 입력 문장을 형태소 분석해서 \"입력 문장\", \"형태소 배열\" 만듬. (필요시 출신국가 등 파라미터 추가)\n",
    "  2. 입력 문장을 \"그대로\" 말뭉치 내 모든 문장에 대해 검색.\n",
    "  3. 벡터 검색 결과 / BM25 검색 결과를 각각 별도로 추출함.\n",
    "  4. 벡터/BM25 결과 일치수치가 100이면 해당 문장과 동일함. 이 경우 올바른 문장이던 틀린 문장이던 말뭉치에 에러정보가 존재함.\n",
    "  5. 공통분모가 존재하고 벡터 < BM25가 유사성이 더 높으면 오타 오류일 확률이 높음. (특히 오타 오류가 끼어있으면)\n",
    "  7. 공통분모가 존재하거 벡터 > BM25가 유사성이 더 높으면 \"의미적으로만\" 비슷할 확률이 높음.\n",
    "\n",
    "# DB 구조\n",
    " - 에러 문장\n",
    " - 에러 문장 벡터\n",
    " - 틀린 형태소 배열\n",
    " - 올바른 형태소 배열\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09db4ef4-67eb-4b39-ac0e-7de939cf33eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에러 문장, 에러 문장 벡터, 틀린 형태소 배열만 OpenSearch에 저장한 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326fefa0-db46-4d7a-b1c6-b8e09ee749b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puju/py_playground/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from opensearchpy import OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ee6c3e-a29b-4882-9192-9335e3a9bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSearch 클라이언트 연결\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': '172.30.1.81', 'port': 9200}],\n",
    "    http_auth=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b44eee-8f1e-4664-b064-cab53ccce6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:01<00:00, 288.45it/s, Materializing param=pooler.dense.weight]\n"
     ]
    }
   ],
   "source": [
    "# embedding 모델 불러오기\n",
    "model = SentenceTransformer(\n",
    "        \"./model/KURE-v1\",\n",
    "        local_files_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4386b6-b951-48ed-ad79-43a1b30ce948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 'korean_test' 생성 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 인덱스 생성 (한국어 분석기 + 벡터 필드)\n",
    "index_name = 'korean_test'\n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"analysis\": {\n",
    "            \"tokenizer\": {\n",
    "                \"nori_tokenizer\": {\n",
    "                    \"type\": \"nori_tokenizer\",\n",
    "                    \"decompound_mode\": \"mixed\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"korean\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"nori_tokenizer\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"original_text\": { # 원본 문자열\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"korean\"\n",
    "            },\n",
    "            \"morphs\": { # 형태소 배열\n",
    "                 \"type\": \"keyword\"\n",
    "            },\n",
    "            \"embedding\": { # 임베딩\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"cosinesimil\",\n",
    "                    \"engine\": \"lucene\"  # nmslib → lucene으로 변경\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 기존 인덱스 삭제 (테스트용)\n",
    "if client.indices.exists(index=index_name):\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "# 인덱스 생성\n",
    "client.indices.create(index=index_name, body=index_body)\n",
    "print(f\"인덱스 '{index_name}' 생성 완료\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb6ba07-4d33-465e-ba80-09206a057f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 말뭉치 불러오기\n",
    "df = pd.read_parquet('말뭉치.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f170b0-9f23-4414-9d68-f654a65b2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표본 번호와 문장으로 그루핑\n",
    "groupped = df.groupby(['표본 번호', '문장'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89f407-fb63-4c16-9f18-284432922b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "말뭉치 저장 중:   0%|▏                                                                                                                 | 309/235902 [00:16<2:43:21, 24.04it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for (i, sentence), df in tqdm(groupped, total=len(groupped), desc=\"말뭉치 저장 중\"):\n",
    "    morphs = []\n",
    "    for __, row in df.iterrows():\n",
    "        if row[\"형태 주석\"] == '0':\n",
    "            continue\n",
    "        morphs.append(row[\"형태 주석\"])\n",
    "    \n",
    "    embedding = model.encode(sentence).tolist()\n",
    "    client.index(\n",
    "        index=index_name,\n",
    "        id=i,\n",
    "        body={\n",
    "            \"original_text\": sentence,\n",
    "            \"morphs\": morphs,\n",
    "            \"embedding\": embedding\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d00d96da-0abf-4aec-ba1f-a5624ef96e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "색인 완료!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 색인 완료 대기\n",
    "client.indices.refresh(index=index_name)\n",
    "print(\"\\n색인 완료!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c3d4a10-ae04-4907-88a7-bb909a54e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"저는 어제 뱡완에 갔어요.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1164481e-b26e-4914-9c9c-5d3fe39c5806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] BM25 검색 결과:\n",
      "------------------------------------------------------------\n",
      "스코어: 9.2223 | 휴일이었지요 어제 학교에 갔어요\n",
      "스코어: 7.4715 | 저는 네팔에 보커라 갔어요.\n",
      "스코어: 7.2801 | 좀 비군해서 저는 집에 갔어요.\n",
      "스코어: 7.2801 | 저는 친구하고 같이 인사동에 갔어요.\n",
      "스코어: 7.0696 | 친구들을 제 집에 갔어요.\n",
      "스코어: 6.9259 | 특히 여름 때 저는 수영장에 친구와 같이 갔어요.\n",
      "스코어: 6.6052 | 저는 작년에 내 친구들을 함께 \"La Palawa\"에 갔어요.\n",
      "스코어: 6.5903 | 저는 홍대 있는 백화점에 갔습니다.\n",
      "스코어: 6.3070 | 집에 갔어요.\n",
      "스코어: 6.3070 | 학교애 갔어요.\n"
     ]
    }
   ],
   "source": [
    "# 1. BM25 검색 (키워드 매칭)\n",
    "print(\"\\n[1] BM25 검색 결과:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "bm25_query = {\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"original_text\": query_text\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "bm25_results = client.search(index=index_name, body=bm25_query)\n",
    "\n",
    "for hit in bm25_results['hits']['hits']:\n",
    "    print(f\"스코어: {hit['_score']:.4f} | {hit['_source']['original_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b4705b6-4668-4b42-b14e-30bd27944bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] 벡터 검색 결과:\n",
      "------------------------------------------------------------\n",
      "스코어: 0.8460 | 페이징 상하에 지난내 갔어요\n",
      "스코어: 0.8421 | 주말에 제주도 갔어요.\n",
      "스코어: 0.8358 | 항쿡에 가 봤어요\n",
      "스코어: 0.8355 | 해운대에 갔어요\n",
      "스코어: 0.8351 | 첫날에는 저는 유니버첼스튜디오에 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2. 벡터 검색 (의미 유사도)\n",
    "print(\"\\n[2] 벡터 검색 결과:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "vector_query = {\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"embedding\": {\n",
    "                \"vector\": query_embedding,\n",
    "                \"k\": 5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "vector_results = client.search(index=index_name, body=vector_query)\n",
    "\n",
    "for hit in vector_results['hits']['hits']:\n",
    "    print(f\"스코어: {hit['_score']:.4f} | {hit['_source']['original_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db723bd7-448d-4685-8f09-f7bffce42570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] 하이브리드 검색 결과:\n",
      "------------------------------------------------------------\n",
      "스코어: 4.6112 | 휴일이었지요 어제 학교에 갔어요\n",
      "스코어: 3.7357 | 저는 네팔에 보커라 갔어요.\n",
      "스코어: 3.6400 | 좀 비군해서 저는 집에 갔어요.\n",
      "스코어: 3.6400 | 저는 친구하고 같이 인사동에 갔어요.\n",
      "스코어: 3.5348 | 친구들을 제 집에 갔어요.\n",
      "스코어: 3.4665 | 해운대에 갔어요\n",
      "스코어: 3.4629 | 특히 여름 때 저는 수영장에 친구와 같이 갔어요.\n",
      "스코어: 3.4155 | 첫날에는 저는 유니버첼스튜디오에 갔습니다.\n",
      "스코어: 3.3718 | 주말에 제주도 갔어요.\n",
      "스코어: 3.3026 | 저는 작년에 내 친구들을 함께 \"La Palawa\"에 갔어요.\n"
     ]
    }
   ],
   "source": [
    "# 3. 하이브리드 검색 (BM25 + 벡터)\n",
    "print(\"\\n[3] 하이브리드 검색 결과:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "hybrid_query = {\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"match\": {\n",
    "                        \"original_text\": {\n",
    "                            \"query\": query_text,\n",
    "                            \"boost\": 0.5  # BM25 가중치\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"knn\": {\n",
    "                        \"embedding\": {\n",
    "                            \"vector\": query_embedding,\n",
    "                            \"k\": 5,\n",
    "                            \"boost\": 0.5  # 벡터 가중치\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "hybrid_results = client.search(index=index_name, body=hybrid_query)\n",
    "\n",
    "for hit in hybrid_results['hits']['hits']:\n",
    "    print(f\"스코어: {hit['_score']:.4f} | {hit['_source']['original_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa33c67-d549-4688-9708-10665b6a323a",
   "metadata": {},
   "source": [
    "# 가설 1차 실행결과\n",
    " - 형태소 분석 아예 안하고, 입력 문장을 바로 말뭉치에서 검색하는 방법 사용해봄\n",
    " - 예상대로, BM25 검색은 대체로 오타 오류를 비교적 잘 잡는 느낌.\n",
    " - 벡터 검색결과가 모호함. 의미적으로는 유사하기 때문에 비슷한 \"표현\" 정보는 가져올 수 있을거 같은데, 결국 다른 오류가 뜨는거 같음.\n",
    "\n",
    "## 그러면...\n",
    " - (일단 하이브리드 방식을 사용한다 가정하고) 검색 결과에 대해 오류가 발생한 \"부분\" 을 다시 뽑아서 이 부분만 원본 문장과 대조해서 동일해 보이는 케이스를 역으로 검색해야 하는가?\n",
    " - 예를 들면, \"저는 어제 병원에 갔어요.\" 라는 올바른 문장을 입력하면 아래와 같은 반환값이 옴.\n",
    "```\n",
    "스코어: 4.1908 | 제 건강은 안 좋아서 자주 아파요.\n",
    "스코어: 3.4652 | 지금 한국에 날씨가 추워서 미나 씨 할아버지 건강이 안 좋아요.\n",
    "스코어: 3.4494 | 안 좋아요.\n",
    "스코어: 3.0841 | 저는 건강을 위해서 생활 안 좋은 습관을 바습니다.\n",
    "스코어: 2.9577 | 하지만 미나 씨 할머니가 건강이 안 좋으셔서 간식을 안 드세요.\n",
    "스코어: 2.9322 | 혼자 가니까 안 좋아 안 좋아요\n",
    "스코어: 2.8821 | 하지만 술을 많이 마시면 건강에 안 좋다.\n",
    "스코어: 2.8630 | 한식도 건강하고 맛있어서 좋아요.\n",
    "스코어: 2.8475 | 하지만 불고기보다 김밥이 더 건강에 좋아요.\n",
    "스코어: 2.6567 | 저는 건강을 위해서 안 좋은 생활 습관을 바꿀 거에요.\n",
    "```\n",
    " - 이 문장들을 전부 뽑아서 형태소 단위로 N-gram 검색을 해서 오류가 존재하는지의 여부를 검사하면, 입력한 문장이 어디에 속하는지 더 잘 알 수 있지 않을까 하는 생각.\n",
    " - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
