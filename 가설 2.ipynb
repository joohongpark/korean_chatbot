{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f8285-fde2-4403-a029-43e9ca6d0c99",
   "metadata": {},
   "source": [
    "# 가설 2\n",
    " - 가설 1차에서 입력 문장을 벡터 / BM25로 검색해봄.\n",
    " - 검색된 문장 자체로는 큰 의미 없는 문장이 나오는거 같아, 형태소 단위로 분석해 볼 예정\n",
    "\n",
    "## 입력 문장 형태소 분리\n",
    " - kiwipiepy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d6f9ca-4d79-4375-b8ce-0f13eed8c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m4 packages\u001b[0m \u001b[2min 2.18s\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 5.91s\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwipiepy\u001b[0m\u001b[2m==0.22.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwipiepy-model\u001b[0m\u001b[2m==0.22.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install kiwipiepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d22c0d84-eb5b-40b5-9f37-8c6cd5b03360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb878ae2-1d86-451e-8d05-e2f6d6c662f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키위 태그\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TagInfo:\n",
    "    desc: str\n",
    "    group: str\n",
    "    score: int  # 0~100\n",
    "\n",
    "TAG_INFO: Dict[str, TagInfo] = {\n",
    "    # =========================\n",
    "    # 체언(N): 문장 성분(주어/목적어/보어 등)의 핵심 재료\n",
    "    # =========================\n",
    "    \"NNG\": TagInfo(desc=\"일반 명사\", group=\"체언(N)\", score=90),\n",
    "    \"NNP\": TagInfo(desc=\"고유 명사\", group=\"체언(N)\", score=85),\n",
    "    \"NNB\": TagInfo(desc=\"의존 명사\", group=\"체언(N)\", score=75),\n",
    "    \"NR\":  TagInfo(desc=\"수사\", group=\"체언(N)\", score=70),\n",
    "    \"NP\":  TagInfo(desc=\"대명사\", group=\"체언(N)\", score=80),\n",
    "\n",
    "    # =========================\n",
    "    # 용언(V): 서술의 핵심(동작/상태/판정)\n",
    "    # =========================\n",
    "    \"VV\":  TagInfo(desc=\"동사\", group=\"용언(V)\", score=90),\n",
    "    \"VA\":  TagInfo(desc=\"형용사\", group=\"용언(V)\", score=90),\n",
    "    \"VX\":  TagInfo(desc=\"보조 용언\", group=\"용언(V)\", score=65),\n",
    "    \"VCP\": TagInfo(desc=\"긍정 지정사(이다)\", group=\"용언(V)\", score=85),\n",
    "    \"VCN\": TagInfo(desc=\"부정 지정사(아니다)\", group=\"용언(V)\", score=85),\n",
    "\n",
    "    # =========================\n",
    "    # 관형사: 체언 수식(정보 추가) — 핵심 성분보단 부수적\n",
    "    # =========================\n",
    "    \"MM\":  TagInfo(desc=\"관형사\", group=\"관형사\", score=50),\n",
    "\n",
    "    # =========================\n",
    "    # 부사(MA): 용언/문장 수식(상황/정도/연결) — 선택적이지만 유용\n",
    "    # =========================\n",
    "    \"MAG\": TagInfo(desc=\"일반 부사\", group=\"부사(MA)\", score=50),\n",
    "    \"MAJ\": TagInfo(desc=\"접속 부사\", group=\"부사(MA)\", score=45),\n",
    "\n",
    "    # =========================\n",
    "    # 감탄사: 독립 발화 가능 — 문장 성분 구성에는 낮은 기여\n",
    "    # =========================\n",
    "    \"IC\":  TagInfo(desc=\"감탄사\", group=\"감탄사\", score=15),\n",
    "\n",
    "    # =========================\n",
    "    # 조사(J): 격/관계 표지(주격, 목적격 등) — 한국어에서 구조 해석에 매우 핵심\n",
    "    # =========================\n",
    "    \"JKS\": TagInfo(desc=\"주격 조사\", group=\"조사(J)\", score=90),\n",
    "    \"JKC\": TagInfo(desc=\"보격 조사\", group=\"조사(J)\", score=85),\n",
    "    \"JKG\": TagInfo(desc=\"관형격 조사\", group=\"조사(J)\", score=80),\n",
    "    \"JKO\": TagInfo(desc=\"목적격 조사\", group=\"조사(J)\", score=90),\n",
    "    \"JKB\": TagInfo(desc=\"부사격 조사\", group=\"조사(J)\", score=80),\n",
    "    \"JKV\": TagInfo(desc=\"호격 조사\", group=\"조사(J)\", score=45),\n",
    "    \"JKQ\": TagInfo(desc=\"인용격 조사\", group=\"조사(J)\", score=75),\n",
    "    \"JX\":  TagInfo(desc=\"보조사\", group=\"조사(J)\", score=60),\n",
    "    \"JC\":  TagInfo(desc=\"접속 조사\", group=\"조사(J)\", score=70),\n",
    "\n",
    "    # =========================\n",
    "    # 어미(E): 문장 종결/연결/시제/높임 등 문법 중심축 — 매우 중요\n",
    "    # =========================\n",
    "    \"EP\":  TagInfo(desc=\"선어말 어미\", group=\"어미(E)\", score=90),\n",
    "    \"EF\":  TagInfo(desc=\"종결 어미\", group=\"어미(E)\", score=95),\n",
    "    \"EC\":  TagInfo(desc=\"연결 어미\", group=\"어미(E)\", score=90),\n",
    "    \"ETN\": TagInfo(desc=\"명사형 전성 어미\", group=\"어미(E)\", score=80),\n",
    "    \"ETM\": TagInfo(desc=\"관형형 전성 어미\", group=\"어미(E)\", score=80),\n",
    "\n",
    "    # =========================\n",
    "    # 접사/어근: 단어 형성(파생) — 문장 골격보단 어휘 확장에 더 기여\n",
    "    # =========================\n",
    "    \"XPN\": TagInfo(desc=\"체언 접두사\", group=\"접두사\", score=35),\n",
    "    \"XSN\": TagInfo(desc=\"명사 파생 접미사\", group=\"접미사(XS)\", score=40),\n",
    "    \"XSV\": TagInfo(desc=\"동사 파생 접미사\", group=\"접미사(XS)\", score=40),\n",
    "    \"XSA\": TagInfo(desc=\"형용사 파생 접미사\", group=\"접미사(XS)\", score=40),\n",
    "    \"XSM\": TagInfo(desc=\"부사 파생 접미사\", group=\"접미사(XS)\", score=35),\n",
    "    \"XR\":  TagInfo(desc=\"어근\", group=\"어근\", score=50),\n",
    "\n",
    "    # =========================\n",
    "    # 부호/외국어/특수문자(S): 구어 문장 자체엔 필수는 아니나, '문장(텍스트) 표현'에는 유의미\n",
    "    # =========================\n",
    "    \"SF\":  TagInfo(desc=\"종결 부호(. ! ?)\", group=\"부호, 외국어, 특수문자(S)\", score=25),\n",
    "    \"SP\":  TagInfo(desc=\"구분 부호(, / : ;)\", group=\"부호, 외국어, 특수문자(S)\", score=15),\n",
    "    \"SS\":  TagInfo(desc=\"인용 부호 및 괄호(' \\\" ( ) [ ] < > { } ― ‘ ’ “ ” ≪ ≫ 등)\", group=\"부호, 외국어, 특수문자(S)\", score=15),\n",
    "    \"SSO\": TagInfo(desc=\"SS 중 여는 부호\", group=\"부호, 외국어, 특수문자(S)\", score=10), # SS로 통일\n",
    "    \"SSC\": TagInfo(desc=\"SS 중 닫는 부호\", group=\"부호, 외국어, 특수문자(S)\", score=10), # SS로 통일\n",
    "    \"SE\":  TagInfo(desc=\"줄임표(…)\", group=\"부호, 외국어, 특수문자(S)\", score=10),\n",
    "    \"SO\":  TagInfo(desc=\"붙임표(- ~)\", group=\"부호, 외국어, 특수문자(S)\", score=10),\n",
    "    \"SW\":  TagInfo(desc=\"기타 특수 문자\", group=\"부호, 외국어, 특수문자(S)\", score=5),\n",
    "    \"SL\":  TagInfo(desc=\"알파벳(A-Z a-z)\", group=\"부호, 외국어, 특수문자(S)\", score=5),\n",
    "    \"SH\":  TagInfo(desc=\"한자\", group=\"부호, 외국어, 특수문자(S)\", score=5),\n",
    "    \"SN\":  TagInfo(desc=\"숫자(0-9)\", group=\"부호, 외국어, 특수문자(S)\", score=10),\n",
    "    \"SB\":  TagInfo(desc=\"순서 있는 글머리(가. 나. 1. 2. 가) 나) 등)\", group=\"부호, 외국어, 특수문자(S)\", score=10), # SN로 통일\n",
    "\n",
    "    # =========================\n",
    "    # 분석 불능: 문장 구성 요소로 활용 불가\n",
    "    # =========================\n",
    "    \"UN\":  TagInfo(desc=\"분석 불능\", group=\"분석 불능\", score=0), # NA\n",
    "\n",
    "    # =========================\n",
    "    # 웹(W): 문장(언어) 자체라기보다 토큰 유형\n",
    "    # =========================\n",
    "    \"W_URL\":     TagInfo(desc=\"URL 주소\", group=\"웹(W)\", score=5), # 삭제\n",
    "    \"W_EMAIL\":   TagInfo(desc=\"이메일 주소\", group=\"웹(W)\", score=5), # 삭제\n",
    "    \"W_HASHTAG\": TagInfo(desc=\"해시태그(#abcd)\", group=\"웹(W)\", score=5), # 삭제\n",
    "    \"W_MENTION\": TagInfo(desc=\"멘션(@abcd)\", group=\"웹(W)\", score=5), # 삭제\n",
    "    \"W_SERIAL\":  TagInfo(desc=\"일련번호(전화번호, 통장번호, IP주소 등)\", group=\"웹(W)\", score=5), # 삭제\n",
    "    \"W_EMOJI\":   TagInfo(desc=\"이모지\", group=\"웹(W)\", score=5), # 삭제\n",
    "\n",
    "    # =========================\n",
    "    # 기타: 특수 표기(사이시옷/덧받침 등) — 표기/형태론 처리에만 국소적으로 중요\n",
    "    # =========================\n",
    "    \"Z_CODA\": TagInfo(desc=\"덧붙은 받침\", group=\"기타\", score=20), # 삭제\n",
    "    \"Z_SIOT\": TagInfo(desc=\"사이시옷\", group=\"기타\", score=20), # 삭제\n",
    "    \"USER0~4\": TagInfo(desc=\"사용자 정의 태그\", group=\"기타\", score=0), # 삭제\n",
    "}\n",
    "\n",
    "def tag(tag_code: str) -> TagInfo:\n",
    "    \"\"\"func('NNG').desc / .group / .score\"\"\"\n",
    "    try:\n",
    "        return TAG_INFO[tag_code]\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Unknown tag: {tag_code!r}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e75a9a9a-489d-459b-a3ed-3c59531d035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kiwipiepy 태그 → 말뭉치 태그 변환\n",
    "TAG_CONVERT = {\"SSO\": \"SS\", \"SSC\": \"SS\", \"SB\": \"SN\", \"UN\": \"NA\"}\n",
    "TAG_REMOVE = {\"W_URL\", \"W_EMAIL\", \"W_HASHTAG\", \"W_MENTION\", \"W_SERIAL\", \"W_EMOJI\", \n",
    "              \"Z_CODA\", \"Z_SIOT\", \"USER0\", \"USER1\", \"USER2\", \"USER3\", \"USER4\"}\n",
    "\n",
    "def preprocess_kiwi(tokens):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        tag = token.tag\n",
    "        form = token.form\n",
    "        # 삭제 대상 태그는 건너뛰기\n",
    "        if tag in TAG_REMOVE:\n",
    "            continue\n",
    "        # 변환 대상 태그는 변환\n",
    "        converted_tag = TAG_CONVERT.get(tag, tag)\n",
    "        result.append((form, converted_tag, token.start, token.len))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30645487-d07a-4cc5-9b73-b7689cb32e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('공부', 'NNG', 0, 2)\n",
      "('가', 'JKS', 2, 1)\n",
      "('힘들', 'VA', 4, 2)\n",
      "('ᆫ', 'ETM', 5, 1)\n",
      "('이', 'NNB', 6, 1)\n",
      "('이', 'VCP', 6, 1)\n",
      "('ᆸ니다', 'EF', 6, 3)\n"
     ]
    }
   ],
   "source": [
    "text = \"공부가 힘든입니다\"\n",
    "\n",
    "kiwi = Kiwi()\n",
    "result = kiwi.tokenize(text)\n",
    "\n",
    "result = preprocess_kiwi(result)\n",
    "for it in result:\n",
    "    print(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6bcbdc-359a-4707-bf99-5f558d899ddd",
   "metadata": {},
   "source": [
    "# 말뭉치와 품사태깅 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b7cbd8-25f8-4086-8e4d-fd1ecc9f68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 말뭉치 불러오기\n",
    "df = pd.read_parquet('말뭉치.parquet.gzip')\n",
    "# 표본 번호와 문장으로 그루핑\n",
    "groupped = df.groupby(['표본 번호', '문장'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ec9ab1-8f64-4df7-b1f1-248fa8c8b712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래서 열두 시에 다 끝난면 자도 돼요.\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "for (i, sentence), df in groupped:\n",
    "    print(sentence)\n",
    "    for it in df.iterrows():\n",
    "        if it[1]['형태 주석'] != '0':\n",
    "            arr.append(it[1]['형태 주석'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feaca5c4-657e-4a17-a458-b8e2f96141ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kiwi.tokenize(\"그래서 열두 시에 다 끝난면 자도 돼요.\")\n",
    "\n",
    "result = preprocess_kiwi(result)\n",
    "\n",
    "kiwi_arr = []\n",
    "\n",
    "for it in result:\n",
    "    kiwi_arr.append(it[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a74434ed-9c84-4a23-939d-c255d45d639d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAJ', 'MM', 'NNB', 'JKB', 'MAG', 'VV', 'EC', 'VV', 'EC', 'VV', 'EF', 'SF']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c433b6-885a-40ab-a15f-5ba876605dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MAJ',\n",
       " 'MM',\n",
       " 'NNB',\n",
       " 'JKB',\n",
       " 'MAG',\n",
       " 'VV',\n",
       " 'ETM',\n",
       " 'NNG',\n",
       " 'VV',\n",
       " 'EC',\n",
       " 'VV',\n",
       " 'EF',\n",
       " 'SF']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiwi_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe7ff08-e4d4-4904-b23f-f45f3380681e",
   "metadata": {},
   "source": [
    "## TODO\n",
    " - 말뭉치의 품사태그와 키위 분석기 품사태그와 약간 다른 부분이 있어서, 말뭉치 문서와 키위 분석기 태그 설명을 보고 맞춰보아야 함.\n",
    " - 일단은 skip 하고, 형태주석 / 키위분석기를 N-gram 기반으로 비교하는 테스트 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15414e00-f12b-47ab-afae-794a6ad38829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말뭉치 형태주석: ['MAJ', 'MM', 'NNB', 'JKB', 'MAG', 'VV', 'EC', 'VV', 'EC', 'VV', 'EF', 'SF']\n",
      "말뭉치 계열:     ['M', 'M', 'N', 'J', 'M', 'V', 'E', 'V', 'E', 'V', 'E', 'S']\n",
      "kiwipiepy 태그:  ['MAJ', 'MM', 'NNB', 'JKB', 'MAG', 'VV', 'ETM', 'NNG', 'VV', 'EC', 'VV', 'EF', 'SF']\n",
      "kiwipiepy 계열:  ['M', 'M', 'N', 'J', 'M', 'V', 'E', 'N', 'V', 'E', 'V', 'E', 'S']\n",
      "\n",
      "  raw_levenshtein_distance: 2\n",
      "  raw_levenshtein_similarity: 0.8462\n",
      "  raw_ngram_similarity: 0.75\n",
      "  cat_levenshtein_distance: 1\n",
      "  cat_levenshtein_similarity: 0.9231\n",
      "  cat_ngram_similarity: 0.8\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "# 품사태그 → 상위 계열 매핑\n",
    "TAG_CATEGORY = {\n",
    "    # 체언 (N)\n",
    "    'NNG': 'N', 'NNP': 'N', 'NNB': 'N', 'NR': 'N', 'NP': 'N',\n",
    "    # 용언 (V)\n",
    "    'VV': 'V', 'VA': 'V', 'VX': 'V', 'VCP': 'V', 'VCN': 'V',\n",
    "    # 조사 (J)\n",
    "    'JKS': 'J', 'JKC': 'J', 'JKG': 'J', 'JKO': 'J',\n",
    "    'JKB': 'J', 'JKV': 'J', 'JKQ': 'J', 'JX': 'J', 'JC': 'J',\n",
    "    # 어미 (E)\n",
    "    'EC': 'E', 'EF': 'E', 'EP': 'E', 'ETN': 'E', 'ETM': 'E',\n",
    "    # 관형사·부사 (M)\n",
    "    'MM': 'M', 'MAG': 'M', 'MAJ': 'M',\n",
    "    # 감탄사 (I)\n",
    "    'IC': 'I',\n",
    "    # 부호 (S)\n",
    "    'SF': 'S', 'SP': 'S', 'SS': 'S', 'SE': 'S', 'SO': 'S', 'SW': 'S',\n",
    "    # 접사·어근 (X)\n",
    "    'XPN': 'X', 'XSN': 'X', 'XSV': 'X', 'XSA': 'X', 'XR': 'X',\n",
    "}\n",
    "\n",
    "\n",
    "def to_categories(arr):\n",
    "    \"\"\"품사태그 배열을 상위 계열 배열로 변환\"\"\"\n",
    "    return [TAG_CATEGORY.get(tag, tag) for tag in arr]\n",
    "\n",
    "\n",
    "def compare_morphs(arr1, arr2, n=2):\n",
    "    \"\"\"두 형태주석 배열을 원본/계열 두 수준으로 비교\"\"\"\n",
    "    def calc(a, b):\n",
    "        dist = Levenshtein.distance(a, b)\n",
    "        max_len = max(len(a), len(b))\n",
    "        sim = 1 - (dist / max_len) if max_len > 0 else 1.0\n",
    "\n",
    "        def get_ngrams(a, n):\n",
    "            return [tuple(a[i:i+n]) for i in range(len(a)-n+1)]\n",
    "        ng1, ng2 = set(get_ngrams(a, n)), set(get_ngrams(b, n))\n",
    "        ng_sim = len(ng1 & ng2) / max(len(ng1), len(ng2)) if ng1 and ng2 else 0.0\n",
    "\n",
    "        return dist, round(sim, 4), round(ng_sim, 4)\n",
    "\n",
    "    # 원본 태그 비교 (세밀)\n",
    "    raw_dist, raw_sim, raw_ng = calc(arr1, arr2)\n",
    "    # 계열 매핑 후 비교 (거시적)\n",
    "    cat_dist, cat_sim, cat_ng = calc(to_categories(arr1), to_categories(arr2))\n",
    "\n",
    "    return {\n",
    "        \"raw_levenshtein_distance\": raw_dist,      # 낮을수록 유사 (0 = 완전 일치)\n",
    "        \"raw_levenshtein_similarity\": raw_sim,      # 높을수록 유사 (1.0 = 완전 일치)\n",
    "        \"raw_ngram_similarity\": raw_ng,             # 높을수록 유사 (1.0 = 완전 일치)\n",
    "        \"cat_levenshtein_distance\": cat_dist,       # 낮을수록 유사 (계열 수준)\n",
    "        \"cat_levenshtein_similarity\": cat_sim,      # 높을수록 유사 (계열 수준)\n",
    "        \"cat_ngram_similarity\": cat_ng,             # 높을수록 유사 (계열 수준)\n",
    "    }\n",
    "\n",
    "\n",
    "# 테스트: 말뭉치 형태주석 vs kiwipiepy 분석 결과\n",
    "result = compare_morphs(arr, kiwi_arr, n=2)\n",
    "print(\"말뭉치 형태주석:\", arr)\n",
    "print(\"말뭉치 계열:    \", to_categories(arr))\n",
    "print(\"kiwipiepy 태그: \", kiwi_arr)\n",
    "print(\"kiwipiepy 계열: \", to_categories(kiwi_arr))\n",
    "print()\n",
    "for k, v in result.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e01019-725a-4659-8c30-700fc17f491d",
   "metadata": {},
   "source": [
    "# 실제 검색 테스트\n",
    " - OpenSearch에서 상위 20개의 결과를 모두 가져와, 검색된 말뭉치들의 품사태그와 입력한 텍스트의 품사들을 N-gram 기반으로 비교\n",
    " - TAG_INFO에 명시된 정보를 이용하여, 중요도가 높은 품사 태그엔 가점을 크게 주어야 함.\n",
    " - 비슷한 그룹끼리 그루핑 하여 체크도 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ktvz6hv87s",
   "metadata": {},
   "source": [
    "## 구현 계획\n",
    "\n",
    "### 목표\n",
    "입력 문장의 오류 유형(오타/문법/혼합)을 판별하고, 말뭉치 내 유사 오류 사례를 검색\n",
    "\n",
    "### 핵심 로직\n",
    "1. **입력 전처리**: kiwipiepy로 형태소 분석 → 품사 태그 배열 생성\n",
    "2. **OpenSearch 검색**: BM25 + 벡터 검색 각각 상위 20개 조회\n",
    "3. **형태소 유사도 계산**: TAG_INFO 가중치 반영한 N-gram 비교\n",
    "4. **오류 유형 추정**: BM25/벡터 스코어 + 형태소 유사도 종합 분석\n",
    "\n",
    "### 흐름도\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           입력 문장                                          │\n",
    "│                    \"저는 어제 뱡완에 갔어요.\"                                  │\n",
    "└───────────────────────────────┬─────────────────────────────────────────────┘\n",
    "                                │\n",
    "                                ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                      [1] 입력 전처리 (kiwipiepy)                             │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│  형태소 분석 → 품사 태그 배열: ['NP', 'JX', 'MAG', 'NNG', 'JKB', ...]       │\n",
    "│  임베딩 벡터 생성: model.encode(입력문장) → [1024차원 벡터]                   │\n",
    "└───────────────────────────────┬─────────────────────────────────────────────┘\n",
    "                                │\n",
    "        ┌───────────────────────┴───────────────────────┐\n",
    "        ▼                                               ▼\n",
    "┌───────────────────────────┐               ┌───────────────────────────┐\n",
    "│  [2-A] BM25 검색 (Top 20)  │               │  [2-B] 벡터 검색 (Top 20)  │\n",
    "│  키워드 매칭 기반          │               │  의미 유사도 기반          │\n",
    "└─────────────┬─────────────┘               └─────────────┬─────────────┘\n",
    "              └─────────────────┬─────────────────────────┘\n",
    "                                ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                    [3] 형태소 유사도 계산 (각 결과에 대해)                     │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│  (A) 레벤슈타인 거리: raw(원본 태그) + cat(상위 계열)                        │\n",
    "│  (B) 가중치 적용 N-gram: TAG_INFO.score로 중요 품사에 가점                   │\n",
    "└───────────────────────────────┬─────────────────────────────────────────────┘\n",
    "                                ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                         [4] 오류 유형 추정                                   │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│  BM25 높음 & 벡터 낮음  →  오타 오류 가능성 ↑                               │\n",
    "│  BM25 낮음 & 벡터 높음  →  문법 오류 가능성 ↑                               │\n",
    "│  둘 다 높음 & 형태소 유사  →  동일/매우 유사 문장                            │\n",
    "└───────────────────────────────┬─────────────────────────────────────────────┘\n",
    "                                ▼\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│  [5] 종합 스코어 계산 & 결과 출력                                            │\n",
    "│  final_score = α×norm_bm25 + β×norm_vector + γ×morph_similarity            │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72b786dd-e3c2-4421-a99f-6b905240c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puju/py_playground/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading weights: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:01<00:00, 294.96it/s, Materializing param=pooler.dense.weight]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# embedding 모델 불러오기\n",
    "model = SentenceTransformer(\n",
    "        \"./model/KURE-v1\",\n",
    "        local_files_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "uwzutwhopla",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSearch 클라이언트 연결\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': '172.30.1.81', 'port': 9200}],\n",
    "    http_auth=None,\n",
    "    use_ssl=False,\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "INDEX_NAME = 'korean_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "gkh1lqlbir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 저는 어제 뱡완에 갔어요.\n",
      "토큰: [('저', 'NP', 0, 1), ('는', 'JX', 1, 1), ('어제', 'MAG', 3, 2), ('뱡완', 'NNP', 6, 2), ('에', 'JKB', 8, 1), ('가', 'VV', 10, 1), ('었', 'EP', 10, 1), ('어요', 'EF', 11, 2), ('.', 'SF', 13, 1)]\n",
      "품사 태그: ['NP', 'JX', 'MAG', 'NNP', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "임베딩 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "# [1] 입력 전처리 함수\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "@dataclass\n",
    "class PreprocessedInput:\n",
    "    \"\"\"전처리된 입력 데이터\"\"\"\n",
    "    text: str\n",
    "    tokens: List[Tuple[str, str, int, int]]  # (form, tag, start, len)\n",
    "    tags: List[str]  # 품사 태그 배열\n",
    "    embedding: List[float]  # 1024차원 벡터\n",
    "\n",
    "def preprocess_input(text: str) -> PreprocessedInput:\n",
    "    \"\"\"입력 문장을 형태소 분석하고 임베딩 벡터 생성\"\"\"\n",
    "    # 형태소 분석\n",
    "    result = kiwi.tokenize(text)\n",
    "    tokens = preprocess_kiwi(result)\n",
    "    tags = [t[1] for t in tokens]\n",
    "    \n",
    "    # 임베딩 생성\n",
    "    embedding = model.encode(text).tolist()\n",
    "    \n",
    "    return PreprocessedInput(\n",
    "        text=text,\n",
    "        tokens=tokens,\n",
    "        tags=tags,\n",
    "        embedding=embedding\n",
    "    )\n",
    "\n",
    "# 테스트\n",
    "test_input = preprocess_input(\"저는 어제 뱡완에 갔어요.\")\n",
    "print(f\"입력 문장: {test_input.text}\")\n",
    "print(f\"토큰: {test_input.tokens}\")\n",
    "print(f\"품사 태그: {test_input.tags}\")\n",
    "print(f\"임베딩 차원: {len(test_input.embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3qu4ik4wde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BM25 검색 결과 Top 5]\n",
      "  20.1484 | 휴일이었지요 어제 학교에 갔어요\n",
      "  16.6537 | 저는 네팔에 보커라 갔어요.\n",
      "  16.1505 | 좀 비군해서 저는 집에 갔어요.\n",
      "  16.1505 | 저는 친구하고 같이 인사동에 갔어요.\n",
      "  15.3742 | 친구들을 제 집에 갔어요.\n",
      "\n",
      "[벡터 검색 결과 Top 5]\n",
      "  0.8460 | 페이징 상하에 지난내 갔어요\n",
      "  0.8421 | 주말에 제주도 갔어요.\n",
      "  0.8358 | 항쿡에 가 봤어요\n",
      "  0.8355 | 해운대에 갔어요\n",
      "  0.8351 | 첫날에는 저는 유니버첼스튜디오에 갔습니다.\n"
     ]
    }
   ],
   "source": [
    "# [2] OpenSearch 검색 함수\n",
    "from typing import Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"검색 결과 단일 항목\"\"\"\n",
    "    doc_id: str\n",
    "    text: str\n",
    "    morphs: List[str]\n",
    "    bm25_score: float = 0.0\n",
    "    vector_score: float = 0.0\n",
    "\n",
    "def search_bm25(query_text: str, k: int = 20) -> List[SearchResult]:\n",
    "    \"\"\"BM25 키워드 검색\"\"\"\n",
    "    query = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"original_text\": query_text\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = client.search(index=INDEX_NAME, body=query)\n",
    "    \n",
    "    return [\n",
    "        SearchResult(\n",
    "            doc_id=hit['_id'],\n",
    "            text=hit['_source']['original_text'],\n",
    "            morphs=hit['_source'].get('morphs', []),\n",
    "            bm25_score=hit['_score']\n",
    "        )\n",
    "        for hit in results['hits']['hits']\n",
    "    ]\n",
    "\n",
    "def search_vector(embedding: List[float], k: int = 20) -> List[SearchResult]:\n",
    "    \"\"\"벡터 kNN 검색\"\"\"\n",
    "    query = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"embedding\": {\n",
    "                    \"vector\": embedding,\n",
    "                    \"k\": k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = client.search(index=INDEX_NAME, body=query)\n",
    "    \n",
    "    return [\n",
    "        SearchResult(\n",
    "            doc_id=hit['_id'],\n",
    "            text=hit['_source']['original_text'],\n",
    "            morphs=hit['_source'].get('morphs', []),\n",
    "            vector_score=hit['_score']\n",
    "        )\n",
    "        for hit in results['hits']['hits']\n",
    "    ]\n",
    "\n",
    "def search_combined(query_text: str, embedding: List[float], k: int = 20) -> Dict[str, SearchResult]:\n",
    "    \"\"\"BM25 + 벡터 검색 결과 병합\"\"\"\n",
    "    bm25_results = search_bm25(query_text, k)\n",
    "    vector_results = search_vector(embedding, k)\n",
    "    \n",
    "    # doc_id 기준으로 병합\n",
    "    combined: Dict[str, SearchResult] = {}\n",
    "    \n",
    "    for r in bm25_results:\n",
    "        combined[r.doc_id] = r\n",
    "    \n",
    "    for r in vector_results:\n",
    "        if r.doc_id in combined:\n",
    "            combined[r.doc_id].vector_score = r.vector_score\n",
    "        else:\n",
    "            combined[r.doc_id] = r\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# 테스트\n",
    "print(\"[BM25 검색 결과 Top 5]\")\n",
    "bm25_results = search_bm25(test_input.text, k=5)\n",
    "for r in bm25_results:\n",
    "    print(f\"  {r.bm25_score:.4f} | {r.text}\")\n",
    "\n",
    "print(\"\\n[벡터 검색 결과 Top 5]\")\n",
    "vector_results = search_vector(test_input.embedding, k=5)\n",
    "for r in vector_results:\n",
    "    print(f\"  {r.vector_score:.4f} | {r.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "o0kv9s89dq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 품사 태그: ['NP', 'JX', 'MAG', 'NNP', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "\n",
      "[휴일이었지요 어제 학교에 갔어요]\n",
      "  결과 morphs: ['NNG', 'VCP', 'EP', 'EF', 'MAG', 'NNG', 'JKB', 'VV', 'EP', 'EF']\n",
      "  유사도: raw_lev=0.4667, cat_lev=0.6, weighted_ng=0.3455, combined=0.4582\n",
      "\n",
      "[저는 네팔에 보커라 갔어요.]\n",
      "  결과 morphs: ['NP', 'JX', 'NNP', 'JKB', 'NNP', 'VV', 'EP', 'EF', 'SF']\n",
      "  유사도: raw_lev=0.8778, cat_lev=0.7778, weighted_ng=0.4855, combined=0.6909\n",
      "\n",
      "[좀 비군해서 저는 집에 갔어요.]\n",
      "  결과 morphs: ['MAG', 'NNG', 'XSA', 'EC', 'NP', 'JX', 'NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "  유사도: raw_lev=0.55, cat_lev=0.5833, weighted_ng=0.4124, combined=0.5049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [3] 형태소 유사도 계산 함수 (가중치 적용)\n",
    "\n",
    "def get_tag_weight(tag: str) -> float:\n",
    "    \"\"\"TAG_INFO에서 품사 태그의 가중치(0~1) 반환\"\"\"\n",
    "    if tag in TAG_INFO:\n",
    "        return TAG_INFO[tag].score / 100.0\n",
    "    return 0.5  # 알 수 없는 태그는 중간값\n",
    "\n",
    "def get_ngrams(arr: List[str], n: int = 2) -> List[Tuple[str, ...]]:\n",
    "    \"\"\"N-gram 생성\"\"\"\n",
    "    return [tuple(arr[i:i+n]) for i in range(len(arr)-n+1)]\n",
    "\n",
    "def weighted_ngram_similarity(tags1: List[str], tags2: List[str], n: int = 2) -> float:\n",
    "    \"\"\"가중치 적용 N-gram 유사도 계산\"\"\"\n",
    "    if len(tags1) < n or len(tags2) < n:\n",
    "        return 0.0\n",
    "    \n",
    "    ngrams1 = get_ngrams(tags1, n)\n",
    "    ngrams2 = get_ngrams(tags2, n)\n",
    "    \n",
    "    # 각 N-gram의 가중치 계산 (N-gram 내 태그들의 평균 가중치)\n",
    "    def ngram_weight(ngram: Tuple[str, ...]) -> float:\n",
    "        return sum(get_tag_weight(t) for t in ngram) / len(ngram)\n",
    "    \n",
    "    # 가중치 적용 교집합 계산\n",
    "    set1 = set(ngrams1)\n",
    "    set2 = set(ngrams2)\n",
    "    common = set1 & set2\n",
    "    \n",
    "    if not common:\n",
    "        return 0.0\n",
    "    \n",
    "    # 공통 N-gram의 가중치 합\n",
    "    common_weight = sum(ngram_weight(ng) for ng in common)\n",
    "    \n",
    "    # 전체 N-gram의 가중치 합 (더 큰 쪽 기준)\n",
    "    total_weight = max(\n",
    "        sum(ngram_weight(ng) for ng in set1),\n",
    "        sum(ngram_weight(ng) for ng in set2)\n",
    "    )\n",
    "    \n",
    "    return common_weight / total_weight if total_weight > 0 else 0.0\n",
    "\n",
    "def weighted_levenshtein_similarity(tags1: List[str], tags2: List[str]) -> float:\n",
    "    \"\"\"가중치 적용 레벤슈타인 유사도 계산\"\"\"\n",
    "    if not tags1 or not tags2:\n",
    "        return 0.0\n",
    "    \n",
    "    # 기본 레벤슈타인 거리\n",
    "    dist = Levenshtein.distance(tags1, tags2)\n",
    "    max_len = max(len(tags1), len(tags2))\n",
    "    base_sim = 1 - (dist / max_len)\n",
    "    \n",
    "    # 중요 품사 일치 보너스 계산\n",
    "    important_tags = {'JKS', 'JKO', 'EF', 'EC', 'VV', 'VA', 'NNG', 'NNP'}\n",
    "    \n",
    "    imp1 = [t for t in tags1 if t in important_tags]\n",
    "    imp2 = [t for t in tags2 if t in important_tags]\n",
    "    \n",
    "    if imp1 and imp2:\n",
    "        imp_common = len(set(imp1) & set(imp2))\n",
    "        imp_total = max(len(set(imp1)), len(set(imp2)))\n",
    "        imp_bonus = (imp_common / imp_total) * 0.1  # 최대 10% 보너스\n",
    "    else:\n",
    "        imp_bonus = 0.0\n",
    "    \n",
    "    return min(base_sim + imp_bonus, 1.0)\n",
    "\n",
    "@dataclass\n",
    "class MorphSimilarity:\n",
    "    \"\"\"형태소 유사도 결과\"\"\"\n",
    "    raw_levenshtein: float  # 원본 태그 레벤슈타인 유사도\n",
    "    cat_levenshtein: float  # 계열 태그 레벤슈타인 유사도\n",
    "    weighted_ngram: float   # 가중치 적용 N-gram 유사도\n",
    "    combined: float         # 종합 유사도\n",
    "\n",
    "def calculate_morph_similarity(input_tags: List[str], result_tags: List[str]) -> MorphSimilarity:\n",
    "    \"\"\"형태소 유사도 종합 계산\"\"\"\n",
    "    if not result_tags:\n",
    "        return MorphSimilarity(0.0, 0.0, 0.0, 0.0)\n",
    "    \n",
    "    # 원본 태그 레벤슈타인 유사도\n",
    "    raw_lev = weighted_levenshtein_similarity(input_tags, result_tags)\n",
    "    \n",
    "    # 계열 변환 후 레벤슈타인 유사도\n",
    "    cat1 = to_categories(input_tags)\n",
    "    cat2 = to_categories(result_tags)\n",
    "    cat_lev = weighted_levenshtein_similarity(cat1, cat2)\n",
    "    \n",
    "    # 가중치 적용 N-gram 유사도 (2-gram, 3-gram 평균)\n",
    "    ng2 = weighted_ngram_similarity(input_tags, result_tags, n=2)\n",
    "    ng3 = weighted_ngram_similarity(input_tags, result_tags, n=3)\n",
    "    weighted_ng = (ng2 * 0.6 + ng3 * 0.4)  # 2-gram에 더 큰 가중치\n",
    "    \n",
    "    # 종합 유사도 (가중 평균)\n",
    "    combined = (raw_lev * 0.3 + cat_lev * 0.3 + weighted_ng * 0.4)\n",
    "    \n",
    "    return MorphSimilarity(\n",
    "        raw_levenshtein=round(raw_lev, 4),\n",
    "        cat_levenshtein=round(cat_lev, 4),\n",
    "        weighted_ngram=round(weighted_ng, 4),\n",
    "        combined=round(combined, 4)\n",
    "    )\n",
    "\n",
    "# 테스트\n",
    "print(\"입력 품사 태그:\", test_input.tags)\n",
    "print()\n",
    "for r in bm25_results[:3]:\n",
    "    sim = calculate_morph_similarity(test_input.tags, r.morphs)\n",
    "    print(f\"[{r.text}]\")\n",
    "    print(f\"  결과 morphs: {r.morphs}\")\n",
    "    print(f\"  유사도: raw_lev={sim.raw_levenshtein}, cat_lev={sim.cat_levenshtein}, \"\n",
    "          f\"weighted_ng={sim.weighted_ngram}, combined={sim.combined}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "h9arn3ut0j8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] 오류 유형 추정 함수\n",
    "from enum import Enum\n",
    "\n",
    "class ErrorType(Enum):\n",
    "    TYPO = \"오타 오류\"           # BM25 높고 벡터 낮음\n",
    "    GRAMMAR = \"문법 오류\"        # BM25 낮고 벡터 높음\n",
    "    MIXED = \"혼합 오류\"          # 둘 다 중간\n",
    "    SIMILAR = \"유사 문장\"        # 둘 다 높음\n",
    "    UNRELATED = \"관련성 낮음\"    # 둘 다 낮음\n",
    "\n",
    "def normalize_bm25_score(score: float, max_score: float = 15.0) -> float:\n",
    "    \"\"\"BM25 스코어를 0~1로 정규화\"\"\"\n",
    "    return min(score / max_score, 1.0)\n",
    "\n",
    "def estimate_error_type(\n",
    "    norm_bm25: float, \n",
    "    norm_vector: float, \n",
    "    morph_sim: float,\n",
    "    threshold: float = 0.15\n",
    ") -> Tuple[ErrorType, str]:\n",
    "    \"\"\"\n",
    "    오류 유형 추정\n",
    "    \n",
    "    Args:\n",
    "        norm_bm25: 정규화된 BM25 스코어 (0~1)\n",
    "        norm_vector: 벡터 유사도 스코어 (0~1)\n",
    "        morph_sim: 형태소 유사도 (0~1)\n",
    "        threshold: 판별 임계값\n",
    "    \n",
    "    Returns:\n",
    "        (오류유형, 판별근거)\n",
    "    \"\"\"\n",
    "    diff = norm_bm25 - norm_vector\n",
    "    \n",
    "    # 둘 다 매우 높으면 유사 문장\n",
    "    if norm_bm25 > 0.7 and norm_vector > 0.8:\n",
    "        return ErrorType.SIMILAR, f\"BM25({norm_bm25:.2f})와 벡터({norm_vector:.2f}) 모두 높음\"\n",
    "    \n",
    "    # 둘 다 낮으면 관련성 낮음\n",
    "    if norm_bm25 < 0.3 and norm_vector < 0.6:\n",
    "        return ErrorType.UNRELATED, f\"BM25({norm_bm25:.2f})와 벡터({norm_vector:.2f}) 모두 낮음\"\n",
    "    \n",
    "    # BM25 >> 벡터: 오타 오류 가능성\n",
    "    if diff > threshold:\n",
    "        return ErrorType.TYPO, f\"BM25({norm_bm25:.2f}) > 벡터({norm_vector:.2f}), 차이={diff:.2f}\"\n",
    "    \n",
    "    # 벡터 >> BM25: 문법 오류 가능성\n",
    "    if diff < -threshold:\n",
    "        return ErrorType.GRAMMAR, f\"벡터({norm_vector:.2f}) > BM25({norm_bm25:.2f}), 차이={-diff:.2f}\"\n",
    "    \n",
    "    # 그 외 혼합\n",
    "    return ErrorType.MIXED, f\"BM25({norm_bm25:.2f}) ≈ 벡터({norm_vector:.2f}), 형태소유사도={morph_sim:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "y39uuqcmrv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [5] 종합 분석 함수\n",
    "\n",
    "@dataclass\n",
    "class AnalysisResult:\n",
    "    \"\"\"분석 결과 단일 항목\"\"\"\n",
    "    doc_id: str\n",
    "    text: str\n",
    "    morphs: List[str]\n",
    "    bm25_score: float\n",
    "    vector_score: float\n",
    "    norm_bm25: float\n",
    "    norm_vector: float\n",
    "    morph_similarity: MorphSimilarity\n",
    "    error_type: ErrorType\n",
    "    error_reason: str\n",
    "    final_score: float\n",
    "\n",
    "def analyze_search_results(\n",
    "    input_data: PreprocessedInput,\n",
    "    k: int = 20,\n",
    "    alpha: float = 0.3,  # BM25 가중치\n",
    "    beta: float = 0.3,   # 벡터 가중치\n",
    "    gamma: float = 0.4   # 형태소 유사도 가중치\n",
    ") -> List[AnalysisResult]:\n",
    "    \"\"\"\n",
    "    검색 및 종합 분석 수행\n",
    "    \n",
    "    Args:\n",
    "        input_data: 전처리된 입력 데이터\n",
    "        k: 검색 결과 개수\n",
    "        alpha, beta, gamma: 최종 스코어 계산 가중치\n",
    "    \n",
    "    Returns:\n",
    "        분석 결과 리스트 (final_score 내림차순 정렬)\n",
    "    \"\"\"\n",
    "    # 검색 수행\n",
    "    combined = search_combined(input_data.text, input_data.embedding, k)\n",
    "    \n",
    "    # BM25 스코어 최대값 찾기 (정규화용)\n",
    "    max_bm25 = max((r.bm25_score for r in combined.values()), default=1.0)\n",
    "    max_bm25 = max(max_bm25, 1.0)  # 0 방지\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for doc_id, sr in combined.items():\n",
    "        # 스코어 정규화\n",
    "        norm_bm25 = sr.bm25_score / max_bm25\n",
    "        norm_vector = sr.vector_score  # 이미 0~1 범위\n",
    "        \n",
    "        # 형태소 유사도 계산\n",
    "        morph_sim = calculate_morph_similarity(input_data.tags, sr.morphs)\n",
    "        \n",
    "        # 오류 유형 추정\n",
    "        error_type, error_reason = estimate_error_type(\n",
    "            norm_bm25, norm_vector, morph_sim.combined\n",
    "        )\n",
    "        \n",
    "        # 최종 스코어 계산\n",
    "        final_score = (\n",
    "            alpha * norm_bm25 +\n",
    "            beta * norm_vector +\n",
    "            gamma * morph_sim.combined\n",
    "        )\n",
    "        \n",
    "        results.append(AnalysisResult(\n",
    "            doc_id=doc_id,\n",
    "            text=sr.text,\n",
    "            morphs=sr.morphs,\n",
    "            bm25_score=sr.bm25_score,\n",
    "            vector_score=sr.vector_score,\n",
    "            norm_bm25=round(norm_bm25, 4),\n",
    "            norm_vector=round(norm_vector, 4),\n",
    "            morph_similarity=morph_sim,\n",
    "            error_type=error_type,\n",
    "            error_reason=error_reason,\n",
    "            final_score=round(final_score, 4)\n",
    "        ))\n",
    "    \n",
    "    # final_score 내림차순 정렬\n",
    "    results.sort(key=lambda x: x.final_score, reverse=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "u56y9g9gtb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] 결과 출력 함수\n",
    "\n",
    "def print_analysis_results(\n",
    "    input_data: PreprocessedInput,\n",
    "    results: List[AnalysisResult],\n",
    "    top_n: int = 10\n",
    "):\n",
    "    \"\"\"분석 결과 출력\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"입력 문장: {input_data.text}\")\n",
    "    print(f\"입력 품사: {input_data.tags}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 오류 유형별 집계\n",
    "    type_counts = {}\n",
    "    for r in results:\n",
    "        t = r.error_type.value\n",
    "        type_counts[t] = type_counts.get(t, 0) + 1\n",
    "    \n",
    "    print(\"\\n[오류 유형 분포]\")\n",
    "    for t, cnt in sorted(type_counts.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {t}: {cnt}건\")\n",
    "    \n",
    "    # 상위 결과 출력\n",
    "    print(f\"\\n[상위 {top_n}개 유사 오류 사례]\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'순위':^4} | {'종합':^6} | {'BM25':^6} | {'벡터':^6} | {'형태소':^6} | {'유형':^10} | 문장\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, r in enumerate(results[:top_n], 1):\n",
    "        print(f\"{i:^4} | {r.final_score:^6.3f} | {r.norm_bm25:^6.3f} | \"\n",
    "              f\"{r.norm_vector:^6.3f} | {r.morph_similarity.combined:^6.3f} | \"\n",
    "              f\"{r.error_type.value:^10} | {r.text[:40]}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # 상위 3개 상세 정보\n",
    "    print(\"\\n[상위 3개 상세 분석]\")\n",
    "    for i, r in enumerate(results[:3], 1):\n",
    "        print(f\"\\n--- {i}위 ---\")\n",
    "        print(f\"문장: {r.text}\")\n",
    "        print(f\"morphs: {r.morphs}\")\n",
    "        print(f\"BM25: {r.bm25_score:.4f} (정규화: {r.norm_bm25:.4f})\")\n",
    "        print(f\"벡터: {r.vector_score:.4f} (정규화: {r.norm_vector:.4f})\")\n",
    "        print(f\"형태소 유사도: raw_lev={r.morph_similarity.raw_levenshtein}, \"\n",
    "              f\"cat_lev={r.morph_similarity.cat_levenshtein}, \"\n",
    "              f\"weighted_ng={r.morph_similarity.weighted_ngram}\")\n",
    "        print(f\"오류 유형: {r.error_type.value}\")\n",
    "        print(f\"판별 근거: {r.error_reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vn5efzht8vd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [7] 통합 검색 함수 (최종 API)\n",
    "\n",
    "def search_and_analyze(query: str, k: int = 20, top_n: int = 10) -> List[AnalysisResult]:\n",
    "    \"\"\"\n",
    "    입력 문장에 대한 오류 분석 및 유사 사례 검색\n",
    "    \n",
    "    Args:\n",
    "        query: 분석할 문장\n",
    "        k: 검색 결과 개수\n",
    "        top_n: 출력할 상위 결과 개수\n",
    "    \n",
    "    Returns:\n",
    "        분석 결과 리스트\n",
    "    \"\"\"\n",
    "    # 1. 입력 전처리\n",
    "    input_data = preprocess_input(query)\n",
    "    \n",
    "    # 2. 검색 및 분석\n",
    "    results = analyze_search_results(input_data, k=k)\n",
    "    \n",
    "    # 3. 결과 출력\n",
    "    print_analysis_results(input_data, results, top_n=top_n)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8q9wz3nwlw",
   "metadata": {},
   "source": [
    "## 테스트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4enuekc3c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 저는 어제 뱡완에 갔어요.\n",
      "입력 품사: ['NP', 'JX', 'MAG', 'NNP', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  문법 오류: 18건\n",
      "  오타 오류: 16건\n",
      "  유사 문장: 2건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.712  | 0.743  | 0.828  | 0.603  |   유사 문장    | 저는 홍대 있는 백화점에 갔습니다.\n",
      " 2   | 0.712  | 0.665  | 0.835  | 0.656  |   문법 오류    | 첫날에는 저는 유니버첼스튜디오에 갔습니다.\n",
      " 3   | 0.695  | 0.704  | 0.836  | 0.582  |   유사 문장    | 해운대에 갔어요\n",
      " 4   | 0.683  | 0.677  | 0.842  | 0.568  |   문법 오류    | 주말에 제주도 갔어요.\n",
      " 5   | 0.551  | 0.802  | 0.000  | 0.776  |   오타 오류    | 저는 친구하고 같이 인사동에 갔어요.\n",
      " 6   | 0.524  | 0.827  | 0.000  | 0.691  |   오타 오류    | 저는 네팔에 보커라 갔어요.\n",
      " 7   | 0.483  | 1.000  | 0.000  | 0.458  |   오타 오류    | 휴일이었지요 어제 학교에 갔어요\n",
      " 8   | 0.482  | 0.000  | 0.832  | 0.582  |   문법 오류    | 홍대에 갔다\n",
      " 9   | 0.471  | 0.000  | 0.830  | 0.554  |   문법 오류    | 지난 주말에 친구하고 명동에 갔어요.\n",
      " 10  | 0.457  | 0.733  | 0.000  | 0.592  |   오타 오류    | 집에 갔어요.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 저는 홍대 있는 백화점에 갔습니다.\n",
      "morphs: ['NP', 'JX', 'NNP', 'VV', 'ETM', 'NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 14.9716 (정규화: 0.7431)\n",
      "벡터: 0.8279 (정규화: 0.8279)\n",
      "형태소 유사도: raw_lev=0.7114, cat_lev=0.7273, weighted_ng=0.4272\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.74)와 벡터(0.83) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 첫날에는 저는 유니버첼스튜디오에 갔습니다.\n",
      "morphs: ['NNG', 'JKB', 'JX', 'NP', 'JX', 'NNP', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 13.3954 (정규화: 0.6648)\n",
      "벡터: 0.8351 (정규화: 0.8351)\n",
      "형태소 유사도: raw_lev=0.7114, cat_lev=0.7273, weighted_ng=0.5609\n",
      "오류 유형: 문법 오류\n",
      "판별 근거: 벡터(0.84) > BM25(0.66), 차이=0.17\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 해운대에 갔어요\n",
      "morphs: ['NNP', 'JKB', 'VV', 'EP', 'EF']\n",
      "BM25: 14.1817 (정규화: 0.7039)\n",
      "벡터: 0.8355 (정규화: 0.8355)\n",
      "형태소 유사도: raw_lev=0.6556, cat_lev=0.5556, weighted_ng=0.546\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.70)와 벡터(0.84) 모두 높음\n"
     ]
    }
   ],
   "source": [
    "# 테스트 1: 오타 오류 문장 (병원 → 뱡완)\n",
    "results1 = search_and_analyze(\"저는 어제 뱡완에 갔어요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9grek7doom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 저는 친구를 같이 영화를 봤어요.\n",
      "입력 품사: ['NP', 'JX', 'NNG', 'JKO', 'MAG', 'NNG', 'JKO', 'VV', 'EP', 'EF', 'SF']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  문법 오류: 18건\n",
      "  오타 오류: 15건\n",
      "  유사 문장: 2건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.832  | 1.000  | 0.878  | 0.671  |   유사 문장    | 혼자 영화를 봤어요.\n",
      " 2   | 0.685  | 0.570  | 0.922  | 0.593  |   문법 오류    | 친구는 영화를 보고 싶었습니다.\n",
      " 3   | 0.665  | 0.807  | 0.908  | 0.377  |   유사 문장    | 친구들 같이 봤다\n",
      " 4   | 0.654  | 0.660  | 0.913  | 0.454  |   문법 오류    | 친구와 같이 영화관에서 영화를 볼 거예요.\n",
      " 5   | 0.642  | 0.613  | 0.926  | 0.450  |   문법 오류    | 친구하고 같이 영화를 보러 가고 싶습니다.\n",
      " 6   | 0.526  | 0.000  | 0.876  | 0.657  |   문법 오류    | 친구하고 쇼핑을 했어요.\n",
      " 7   | 0.523  | 0.000  | 0.868  | 0.657  |   문법 오류    | 친구하고 이야기를 했습니다.\n",
      " 8   | 0.503  | 0.000  | 0.876  | 0.600  |   문법 오류    | 친구하고 같이 집에 갔어요.\n",
      " 9   | 0.500  | 0.000  | 0.865  | 0.600  |   문법 오류    | 친구와 같이 백화점에 갔어요.\n",
      " 10  | 0.497  | 0.781  | 0.000  | 0.657  |   오타 오류    | 휴가 때 역사 드라마와 영화를 봤다.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 혼자 영화를 봤어요.\n",
      "morphs: ['MAG', 'NNG', 'JKO', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 28.0258 (정규화: 1.0000)\n",
      "벡터: 0.8776 (정규화: 0.8776)\n",
      "형태소 유사도: raw_lev=0.7364, cat_lev=0.6364, weighted_ng=0.6474\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(1.00)와 벡터(0.88) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 친구는 영화를 보고 싶었습니다.\n",
      "morphs: ['NNG', 'JX', 'NNG', 'JKO', 'VV', 'EC', 'VX', 'EP', 'EF', 'SF']\n",
      "BM25: 15.9645 (정규화: 0.5696)\n",
      "벡터: 0.9219 (정규화: 0.9219)\n",
      "형태소 유사도: raw_lev=0.6255, cat_lev=0.7273, weighted_ng=0.4679\n",
      "오류 유형: 문법 오류\n",
      "판별 근거: 벡터(0.92) > BM25(0.57), 차이=0.35\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 친구들 같이 봤다\n",
      "morphs: ['NNG', 'XSN', 'MAG', 'VV', 'EP', 'EF']\n",
      "BM25: 22.6105 (정규화: 0.8068)\n",
      "벡터: 0.9077 (정규화: 0.9077)\n",
      "형태소 유사도: raw_lev=0.5295, cat_lev=0.4545, weighted_ng=0.2051\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.81)와 벡터(0.91) 모두 높음\n"
     ]
    }
   ],
   "source": [
    "# 테스트 2: 문법 오류 문장 (조사 오류)\n",
    "results2 = search_and_analyze(\"저는 친구를 같이 영화를 봤어요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75p1z650oaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 저는 어제 병원에 갔어요.\n",
      "입력 품사: ['NP', 'JX', 'MAG', 'NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  문법 오류: 16건\n",
      "  오타 오류: 16건\n",
      "  유사 문장: 4건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.783  | 0.986  | 0.836  | 0.592  |   유사 문장    | 휴일이었지요 어제 학교에 갔어요\n",
      " 2   | 0.748  | 0.758  | 0.811  | 0.693  |   유사 문장    | 집에 갔어요.\n",
      " 3   | 0.686  | 0.806  | 0.825  | 0.491  |   유사 문장    | 친구도 부무님도 빨리 병원에 가라고 해서 병원에 갔다.\n",
      " 4   | 0.623  | 0.818  | 0.844  | 0.310  |   유사 문장    | 저는 작년 여름에 배탈이 심한 데다가 설사도 해서 병원에 갔다.\n",
      " 5   | 0.519  | 0.000  | 0.822  | 0.681  |   문법 오류    | 호텔에서 한 밤에 지냈었어\n",
      " 6   | 0.517  | 0.800  | 0.000  | 0.693  |   오타 오류    | 저는 친구하고 같이 인사동에 갔어요.\n",
      " 7   | 0.514  | 0.000  | 0.851  | 0.648  |   문법 오류    | 지난 주말에 감기에 걸렸습니다.\n",
      " 8   | 0.506  | 0.000  | 0.823  | 0.648  |   문법 오류    | 지난 주말에 술집에 갔어요.\n",
      " 9   | 0.503  | 0.665  | 0.000  | 0.759  |   오타 오류    | 하지만 저는 매일 친국하고 같이 영화과에 갔습니다.\n",
      " 10  | 0.494  | 0.825  | 0.000  | 0.617  |   오타 오류    | 저는 네팔에 보커라 갔어요.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 휴일이었지요 어제 학교에 갔어요\n",
      "morphs: ['NNG', 'VCP', 'EP', 'EF', 'MAG', 'NNG', 'JKB', 'VV', 'EP', 'EF']\n",
      "BM25: 21.7737 (정규화: 0.9858)\n",
      "벡터: 0.8362 (정규화: 0.8362)\n",
      "형태소 유사도: raw_lev=0.6, cat_lev=0.6, weighted_ng=0.5793\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.99)와 벡터(0.84) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 집에 갔어요.\n",
      "morphs: ['NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 16.7393 (정규화: 0.7578)\n",
      "벡터: 0.8111 (정규화: 0.8111)\n",
      "형태소 유사도: raw_lev=0.7667, cat_lev=0.6667, weighted_ng=0.6563\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.76)와 벡터(0.81) 모두 높음\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 친구도 부무님도 빨리 병원에 가라고 해서 병원에 갔다.\n",
      "morphs: ['NNG', 'JX', 'NNG', 'XSN', 'JX', 'MAG', 'NNG', 'JKB', 'VV', 'EC', 'VV', 'EC', 'NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 17.8124 (정규화: 0.8064)\n",
      "벡터: 0.8253 (정규화: 0.8253)\n",
      "형태소 유사도: raw_lev=0.5194, cat_lev=0.5, weighted_ng=0.4624\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.81)와 벡터(0.83) 모두 높음\n"
     ]
    }
   ],
   "source": [
    "# 테스트 3: 올바른 문장\n",
    "results3 = search_and_analyze(\"저는 어제 병원에 갔어요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ng6e79ycns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 공부가 힘든입니다.\n",
      "입력 품사: ['NNG', 'JKS', 'VA', 'ETM', 'NNB', 'VCP', 'EF', 'SF']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  문법 오류: 18건\n",
      "  오타 오류: 18건\n",
      "  유사 문장: 2건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.730  | 0.920  | 0.882  | 0.472  |   유사 문장    | 힘든 것도 있어요.\n",
      " 2   | 0.717  | 0.958  | 0.897  | 0.402  |   유사 문장    | 힘든 것 같아서\n",
      " 3   | 0.570  | 0.000  | 0.898  | 0.752  |   문법 오류    | 학생 생활이 좀 어려운 편이다.\n",
      " 4   | 0.531  | 0.958  | 0.000  | 0.610  |   오타 오류    | 힘든 거예요\n",
      " 5   | 0.438  | 0.841  | 0.000  | 0.464  |   오타 오류    | 힘든 것이 힘들기 때문이에요 곳 가따요\n",
      " 6   | 0.422  | 1.000  | 0.000  | 0.306  |   오타 오류    | 힘든 한국어?\n",
      " 7   | 0.411  | 0.793  | 0.000  | 0.433  |   오타 오류    | 힘든 시간이 췹게 지난 수 있습니다\n",
      " 8   | 0.406  | 0.741  | 0.000  | 0.460  |   오타 오류    | 한국 생활이 힘든다니까 걱정 많이 했어요.\n",
      " 9   | 0.406  | 0.000  | 0.891  | 0.348  |   문법 오류    | 학생 생활이 좀 피곤합니다.\n",
      " 10  | 0.400  | 0.793  | 0.000  | 0.405  |   오타 오류    | 한국 생활이 힘들고 너무 힘든합니다.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 힘든 것도 있어요.\n",
      "morphs: ['VA', 'ETM', 'NNB', 'JX', 'VV', 'EF', 'SF']\n",
      "BM25: 15.4701 (정규화: 0.9198)\n",
      "벡터: 0.8819 (정규화: 0.8819)\n",
      "형태소 유사도: raw_lev=0.55, cat_lev=0.625, weighted_ng=0.2996\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.92)와 벡터(0.88) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 힘든 것 같아서\n",
      "morphs: ['VA', 'ETM', 'NNB', 'VA', 'EC']\n",
      "BM25: 16.1166 (정규화: 0.9582)\n",
      "벡터: 0.8969 (정규화: 0.8969)\n",
      "형태소 유사도: raw_lev=0.4, cat_lev=0.625, weighted_ng=0.2367\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.96)와 벡터(0.90) 모두 높음\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 학생 생활이 좀 어려운 편이다.\n",
      "morphs: ['NNG', 'NNG', 'JKS', 'MAG', 'VA', 'ETM', 'NNB', 'VCP', 'EF', 'SF']\n",
      "BM25: 0.0000 (정규화: 0.0000)\n",
      "벡터: 0.8977 (정규화: 0.8977)\n",
      "형태소 유사도: raw_lev=0.9, cat_lev=0.8, weighted_ng=0.6058\n",
      "오류 유형: 문법 오류\n",
      "판별 근거: 벡터(0.90) > BM25(0.00), 차이=0.90\n"
     ]
    }
   ],
   "source": [
    "# 테스트 4: 어미 오류 문장\n",
    "results4 = search_and_analyze(\"공부가 힘든입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ca9b5e6-5c6e-4d2b-a8b0-e47b7a43704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 내 월꺼 아네 있는데요\n",
      "입력 품사: ['NP', 'JKG', 'NNG', 'VV', 'EC', 'VX', 'EC', 'JX']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  오타 오류: 19건\n",
      "  문법 오류: 19건\n",
      "  유사 문장: 1건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.614  | 0.820  | 0.817  | 0.308  |   유사 문장    | 한 통장은 내 용돈으로 만든다.\n",
      " 2   | 0.520  | 1.000  | 0.000  | 0.551  |   오타 오류    | 항상 내 도전이 기다리고 있다\n",
      " 3   | 0.470  | 0.881  | 0.000  | 0.514  |   오타 오류    | 항상 내 이야기를 자주 들어준다.\n",
      " 4   | 0.463  | 0.000  | 0.793  | 0.564  |   문법 오류    | 제 집이 좀 보고 싶어요.\n",
      " 5   | 0.412  | 0.000  | 0.825  | 0.411  |   문법 오류    | 제 생일이 있습니다.\n",
      " 6   | 0.412  | 0.000  | 0.825  | 0.411  |   문법 오류    | 제 생일이 있습니다.\n",
      " 7   | 0.402  | 0.000  | 0.799  | 0.406  |   문법 오류    | 제 이름은 <name>입니다.\n",
      " 8   | 0.402  | 0.000  | 0.795  | 0.408  |   문법 오류    | 저는 돈을 많지 않아요.\n",
      " 9   | 0.402  | 0.000  | 0.795  | 0.408  |   문법 오류    | 저는 돈을 많지 않아요.\n",
      " 10  | 0.392  | 0.915  | 0.000  | 0.293  |   오타 오류    | 흠 성경은 내 성격은\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 한 통장은 내 용돈으로 만든다.\n",
      "morphs: ['MM', 'NNG', 'JX', 'NP', 'JKG', 'NNG', 'JKB', 'VV', 'EF', 'SF']\n",
      "BM25: 10.7626 (정규화: 0.8198)\n",
      "벡터: 0.8174 (정규화: 0.8174)\n",
      "형태소 유사도: raw_lev=0.2667, cat_lev=0.5, weighted_ng=0.194\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(0.82)와 벡터(0.82) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 항상 내 도전이 기다리고 있다\n",
      "morphs: ['MAG', 'NP', 'JKG', 'NNG', 'JKS', 'VV', 'EC', 'VX', 'EF']\n",
      "BM25: 13.1283 (정규화: 1.0000)\n",
      "벡터: 0.0000 (정규화: 0.0000)\n",
      "형태소 유사도: raw_lev=0.6156, cat_lev=0.6667, weighted_ng=0.4162\n",
      "오류 유형: 오타 오류\n",
      "판별 근거: BM25(1.00) > 벡터(0.00), 차이=1.00\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 항상 내 이야기를 자주 들어준다.\n",
      "morphs: ['MAG', 'NP', 'JKG', 'NNG', 'JKO', 'MAG', 'VV', 'EC', 'VX', 'EF', 'SF']\n",
      "BM25: 11.5619 (정규화: 0.8807)\n",
      "벡터: 0.0000 (정규화: 0.0000)\n",
      "형태소 유사도: raw_lev=0.6055, cat_lev=0.6364, weighted_ng=0.3547\n",
      "오류 유형: 오타 오류\n",
      "판별 근거: BM25(0.88) > 벡터(0.00), 차이=0.88\n"
     ]
    }
   ],
   "source": [
    "# 내 테스트\n",
    "results4 = search_and_analyze(\"내 월꺼 아네 있는데요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bd480ad-6c33-458d-bf16-3c2a6c852466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "입력 문장: 제 집에 가고 싶어요.\n",
      "입력 품사: ['NP', 'JKG', 'NNG', 'JKB', 'VV', 'EC', 'VX', 'EF', 'SF']\n",
      "================================================================================\n",
      "\n",
      "[오류 유형 분포]\n",
      "  문법 오류: 19건\n",
      "  오타 오류: 14건\n",
      "  유사 문장: 1건\n",
      "\n",
      "[상위 10개 유사 오류 사례]\n",
      "--------------------------------------------------------------------------------\n",
      " 순위  |   종합   |  BM25  |   벡터   |  형태소   |     유형     | 문장\n",
      "--------------------------------------------------------------------------------\n",
      " 1   | 0.885  | 1.000  | 0.918  | 0.775  |   유사 문장    | 제 집이 좀 보고 싶어요.\n",
      " 2   | 0.727  | 0.644  | 0.858  | 0.691  |   문법 오류    | 한국에 가고 싶어요.\n",
      " 3   | 0.671  | 0.643  | 0.856  | 0.552  |   문법 오류    | 친구들을 제 집에 갔어요.\n",
      " 4   | 0.668  | 0.681  | 0.855  | 0.517  |   문법 오류    | 집에서 쉬기는커녕 집에 가고 싶지 않다.\n",
      " 5   | 0.651  | 0.599  | 0.905  | 0.500  |   문법 오류    | 집에 갔어요.\n",
      " 6   | 0.640  | 0.607  | 0.860  | 0.500  |   문법 오류    | 친구하고 같이 집에 갔어요.\n",
      " 7   | 0.575  | 0.000  | 0.864  | 0.788  |   문법 오류    | 지금 옛날에 돌아가고 싶어요.\n",
      " 8   | 0.556  | 0.000  | 0.864  | 0.742  |   문법 오류    | 저는 가족은 보고 싶어요.\n",
      " 9   | 0.549  | 0.000  | 0.859  | 0.730  |   문법 오류    | 집에서 요리를 하고 싶습니다.\n",
      " 10  | 0.530  | 0.751  | 0.000  | 0.762  |   오타 오류    | 제 취미로 요리를 배우고 싶어요.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[상위 3개 상세 분석]\n",
      "\n",
      "--- 1위 ---\n",
      "문장: 제 집이 좀 보고 싶어요.\n",
      "morphs: ['NP', 'JKG', 'NNG', 'JKS', 'MAG', 'VV', 'EC', 'VX', 'EF', 'SF']\n",
      "BM25: 20.8794 (정규화: 1.0000)\n",
      "벡터: 0.9179 (정규화: 0.9179)\n",
      "형태소 유사도: raw_lev=0.88, cat_lev=0.9, weighted_ng=0.6014\n",
      "오류 유형: 유사 문장\n",
      "판별 근거: BM25(1.00)와 벡터(0.92) 모두 높음\n",
      "\n",
      "--- 2위 ---\n",
      "문장: 한국에 가고 싶어요.\n",
      "morphs: ['NNP', 'JKB', 'VV', 'EC', 'VX', 'EF', 'SF']\n",
      "BM25: 13.4457 (정규화: 0.6440)\n",
      "벡터: 0.8578 (정규화: 0.8578)\n",
      "형태소 유사도: raw_lev=0.7417, cat_lev=0.7778, weighted_ng=0.5877\n",
      "오류 유형: 문법 오류\n",
      "판별 근거: 벡터(0.86) > BM25(0.64), 차이=0.21\n",
      "\n",
      "--- 3위 ---\n",
      "문장: 친구들을 제 집에 갔어요.\n",
      "morphs: ['NNG', 'XSN', 'JKO', 'NP', 'JKG', 'NNG', 'JKB', 'VV', 'EP', 'EF', 'SF']\n",
      "BM25: 13.4264 (정규화: 0.6430)\n",
      "벡터: 0.8563 (정규화: 0.8563)\n",
      "형태소 유사도: raw_lev=0.6205, cat_lev=0.6364, weighted_ng=0.4382\n",
      "오류 유형: 문법 오류\n",
      "판별 근거: 벡터(0.86) > BM25(0.64), 차이=0.21\n"
     ]
    }
   ],
   "source": [
    "# 내 테스트\n",
    "results4 = search_and_analyze(\"제 집에 가고 싶어요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e84a9-b085-4dd9-8b9d-c49e8b121d76",
   "metadata": {},
   "source": [
    "# 테스트 결과\n",
    " - 입력 문장과 오류 문장을 단순 비교하는 방식엔 확실히 한계가 있는듯 함.\n",
    " - \"조금 나아졌다\" 뿐이지, 여전히 입력 문장의 에러와 유사한 에러케이스를 찾는데는 힘들어 보임.\n",
    "\n",
    "# 개선 방안\n",
    " - 말뭉치 샘플 내 존재하는 에러 케이스와 교정 형태소를 활용하면 좋을거 같다는 생각이 듬.\n",
    " - N-gram 검색을 에러 케이스까지 포함시킨다면?\n",
    " - 예를 들면 ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
